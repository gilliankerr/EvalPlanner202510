<!DOCTYPE html>
<!-- saved from url=(0145)file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Black Health Alliance ‚Äî All Programs Evaluation Plan</title>
    <style>
        
    @media print {
      .no-print { display: none; }
      .page-break { page-break-before: always; }
    }
    
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
      line-height: 1.6;
      color: #1e293b;
      max-width: 1200px;
      margin: 0 auto;
      padding: 2rem;
    }
    
    h1:first-of-type {
      font-size: 2.5rem;
      font-weight: 700;
      color: #0f172a;
      margin: 2rem 0 1rem 0;
      padding-bottom: 1rem;
      border-bottom: 3px solid #2563eb;
      text-align: center;
    }
    
    .subtitle {
      text-align: center;
      color: #64748b;
      font-size: 1.1rem;
      margin-bottom: 3rem;
      font-weight: 400;
    }
    
    h2 {
      font-size: 1.75rem;
      font-weight: 700;
      color: #1e293b;
      margin: 3rem 0 1.5rem 0;
      padding-bottom: 0.75rem;
      border-bottom: 2px solid #e2e8f0;
      position: relative;
    }
    
    h2::before {
      content: '';
      position: absolute;
      bottom: -2px;
      left: 0;
      width: 60px;
      height: 2px;
      background: #2563eb;
    }
    
    h3 {
      font-size: 1.375rem;
      font-weight: 600;
      color: #374151;
      margin: 2.5rem 0 1rem 0;
      padding-left: 1rem;
      border-left: 4px solid #3b82f6;
    }
    
    h4 {
      font-size: 1.25rem;
      font-weight: 500;
      color: #4b5563;
      margin: 2rem 0 0.75rem 0;
    }
    
    p {
      margin-bottom: 1.25rem;
      line-height: 1.7;
      color: #374151;
    }
    
    ul, ol {
      margin: 1rem 0 1.5rem 0;
      padding-left: 2rem;
    }
    
    li {
      margin-bottom: 0.5rem;
      line-height: 1.6;
      color: #374151;
    }
    
    strong {
      font-weight: 600;
      color: #1e293b;
    }
    
    a {
      color: #2563eb;
      text-decoration: underline;
      font-weight: 500;
      transition: color 0.2s ease;
    }
    
    a:hover {
      color: #1d4ed8;
      text-decoration: underline;
    }
    
    a:visited {
      color: #7c3aed;
    }
    
    table {
      width: 100%;
      border-collapse: collapse;
      margin: 2rem 0;
      background: white;
      border-radius: 12px;
      overflow: hidden;
      box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -1px rgba(0, 0, 0, 0.06);
      border: 1px solid #e5e7eb;
    }
    
    .logic-model-container {
      margin: 2.5rem 0;
      padding: 1rem;
      background: #f8fafc;
      border-radius: 16px;
      border: 2px solid #3b82f6;
      overflow-x: auto;
    }
    
    .logic-model-table {
      margin: 0;
      box-shadow: 0 8px 16px -4px rgba(0, 0, 0, 0.1);
      border: 2px solid #3b82f6;
      table-layout: fixed;
      width: 100%;
    }
    
    .logic-model-table th {
      padding: 0.6rem 0.8rem;
      font-size: 0.7rem;
      font-weight: 600;
    }
    
    .logic-model-table td {
      padding: 0.75rem 0.8rem;
      vertical-align: top;
      line-height: 1.4;
      background: white;
      border-right: 1px solid #e2e8f0;
      font-size: 0.75rem;
      word-wrap: break-word;
    }
    
    .logic-model-table td:last-child {
      border-right: none;
    }
    
    .logic-model-table tbody tr:hover {
      background: #f1f5f9;
    }
    
    th {
      background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
      padding: 1rem 1.5rem;
      font-weight: 600;
      text-align: left;
      color: #1e293b;
      border-bottom: 2px solid #e2e8f0;
      font-size: 0.9rem;
      text-transform: uppercase;
      letter-spacing: 0.025em;
      position: sticky;
      top: 0;
      z-index: 10;
    }
    
    td {
      padding: 1rem 1.5rem;
      border-bottom: 1px solid #f1f5f9;
      color: #374151;
      vertical-align: top;
      line-height: 1.5;
      font-size: 0.875rem;
    }
    
    tbody tr:hover {
      background-color: #f8fafc;
      transition: background-color 0.15s ease;
    }
    
    tbody tr:last-child td {
      border-bottom: none;
    }
    
    tbody tr:nth-child(even) {
      background-color: #fafbfc;
    }
    
    tbody tr:nth-child(even):hover {
      background-color: #f1f5f9;
    }

    caption {
      caption-side: top;
      padding: 1rem 0;
      font-weight: 600;
      color: #1e293b;
      font-size: 1.1rem;
    }

    .intro-section {
      background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
      padding: 2rem;
      border-radius: 12px;
      margin: 2rem 0;
      border-left: 4px solid #0ea5e9;
    }

    .content-section {
      margin: 3rem 0;
      padding: 0 1rem;
    }

    @media (max-width: 768px) {
      h1:first-of-type {
        font-size: 2rem;
      }
      
      h2 {
        font-size: 1.5rem;
      }
      
      h3 {
        font-size: 1.25rem;
      }
      
      table {
        font-size: 0.875rem;
      }
      
      th, td {
        padding: 0.75rem 1rem;
      }
      
      .content-section {
        padding: 0 0.5rem;
      }
    }

    .toc-item {
      padding: 0.5rem 0.75rem;
      border-radius: 6px;
      transition: all 0.15s ease;
    }
    
    .toc-level-1 {
      margin-left: 0;
    }
    
    .toc-level-2 {
      margin-left: 0.5rem;
    }
    
    .toc-level-3 {
      margin-left: 1rem;
    }
    
    .toc-item:hover {
      background-color: #f1f5f9;
      transform: translateX(4px);
    }
    
    .toc-item a {
      color: #475569;
      text-decoration: underline;
      font-weight: 500;
    }
    
    .toc-item a:hover {
      color: #2563eb;
    }
    
    .highlight-box {
      background: linear-gradient(135deg, #eff6ff 0%, #dbeafe 100%);
      border-left: 4px solid #2563eb;
      padding: 1.5rem;
      margin: 1.5rem 0;
      border-radius: 0 12px 12px 0;
      box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
      position: relative;
    }
    
    .highlight-box::before {
      content: "üí°";
      position: absolute;
      top: 1rem;
      left: -0.75rem;
      background: #2563eb;
      color: white;
      width: 1.5rem;
      height: 1.5rem;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.75rem;
    }
    
    .warning-box {
      background: linear-gradient(135deg, #fffbeb 0%, #fef3c7 100%);
      border-left: 4px solid #d97706;
      padding: 1.5rem;
      margin: 1.5rem 0;
      border-radius: 0 12px 12px 0;
      box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
      position: relative;
    }
    
    .warning-box::before {
      content: "‚ö†Ô∏è";
      position: absolute;
      top: 1rem;
      left: -0.75rem;
      background: #d97706;
      color: white;
      width: 1.5rem;
      height: 1.5rem;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.75rem;
    }
    
    .intro-section {
      background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
      padding: 2rem;
      border-radius: 12px;
      margin: 2rem 0;
      border-left: 4px solid #0ea5e9;
      box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
      position: relative;
    }
    
    .intro-section::before {
      content: "üìã";
      position: absolute;
      top: 1.5rem;
      left: -0.75rem;
      background: #0ea5e9;
      color: white;
      width: 1.5rem;
      height: 1.5rem;
      border-radius: 50%;
      display: flex;
      align-items: center;
      justify-content: center;
      font-size: 0.75rem;
    }
    
    .error-message {
      background: #fee2e2;
      border: 1px solid #fca5a5;
      color: #dc2626;
      padding: 1rem;
      border-radius: 8px;
      margin: 1rem 0;
    }
    
    .hljs {
      background: #f8fafc;
      color: #1e293b;
      padding: 1.5rem;
      border-radius: 8px;
      border: 1px solid #e2e8f0;
      margin: 1.5rem 0;
      overflow-x: auto;
      line-height: 1.5;
    }
    
    .hljs-comment { color: #64748b; font-style: italic; }
    .hljs-keyword { color: #7c3aed; font-weight: 600; }
    .hljs-string { color: #059669; }
    .hljs-number { color: #dc2626; }
    .hljs-function { color: #2563eb; }
    .hljs-variable { color: #b45309; }
    
    .timeline-table,
    .stakeholder-table,
    .evaluation-table,
    .metrics-table {
      background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%);
      border-left: 4px solid #2563eb;
    }
    
    .timeline-table th,
    .stakeholder-table th,
    .evaluation-table th,
    .metrics-table th {
      background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
      color: #1e293b;
    }
    
    .standard-table {
      background: white;
      border-left: 4px solid #6b7280;
    }
    
    .standard-table th {
      background: linear-gradient(135deg, #f8fafc 0%, #f1f5f9 100%);
      color: #1e293b;
    }
    
    @media (max-width: 768px) {
      .logic-model-diagram {
        padding: 1rem;
        margin: 2rem 0;
      }
      
      .logic-model-svg {
        width: 100%;
        height: auto;
      }
      
      table {
        display: block;
        overflow-x: auto;
        white-space: nowrap;
        border-radius: 8px;
        margin: 1rem 0;
      }
      
      table.timeline-table,
      table.stakeholder-table,
      table.evaluation-table,
      table.metrics-table,
      table.standard-table {
        min-width: 600px;
      }
      
      .highlight-box,
      .warning-box,
      .intro-section {
        margin: 1rem 0;
        padding: 1rem;
        border-radius: 0 8px 8px 0;
      }
      
      .highlight-box::before,
      .warning-box::before,
      .intro-section::before {
        display: none;
      }
      
      .hljs {
        padding: 1rem;
        font-size: 0.875rem;
        margin: 1rem 0;
      }
    }
    
    @media (max-width: 480px) {
      .logic-model-diagram {
        padding: 0.75rem;
      }
      
      .logic-model-diagram h4 {
        font-size: 1rem;
        margin-bottom: 1rem;
      }
      
      table {
        font-size: 0.75rem;
      }
      
      th, td {
        padding: 0.5rem 0.75rem;
      }
      
      .highlight-box,
      .warning-box,
      .intro-section {
        padding: 0.75rem;
        margin: 0.75rem 0;
      }
    }
    
    .flex {
      display: flex;
    }
    
    .max-w-6xl {
      max-width: 1200px;
    }
    
    .report-container {
      max-width: 1200px;
      margin: 0 auto;
      padding: 0 1rem;
    }
    
    .mx-auto {
      margin-left: auto;
      margin-right: auto;
    }
  
    </style>
</head>
<body>
    <div class="report-container">
        <div style="background: white; padding: 2rem; border-radius: 12px; box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1); margin-bottom: 2rem;">
            <h3 style="margin: 0 0 1rem 0; color: #1e293b; font-size: 1.25rem;">Table of Contents</h3>
            <div class="toc-item toc-level-1"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#black-health-alliance-all-programs-draft-evaluation-plan">Black Health Alliance ‚Äî All Programs Draft Evaluation Plan</a></div><div class="toc-item toc-level-2"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#program-summary-and-analysis">Program summary and analysis</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#summary-of-the-program">Summary of the program</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#program-overview">Program overview</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#activities">Activities</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#key-management-processes">Key management processes</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#main-interest-groups">Main interest groups</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#areas-of-evaluation-focus">Areas of evaluation focus</a></div><div class="toc-item toc-level-2"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#program-evaluation-plan">Program evaluation plan</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#evaluation-objectives">Evaluation objectives</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#evaluation-questions">Evaluation questions</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#logic-model">Logic model</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#evaluation-framework-for-all-programs">Evaluation framework for All Programs</a></div><div class="toc-item toc-level-2"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#evaluation-phases">Evaluation phases</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#overview">Overview</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#phase-1-engage-the-project-sponsor-team-members-and-key-decision-makers">Phase 1. Engage the project sponsor, team members, and key decision-makers</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#phase-2-define-evaluation-objectives-and-questions">Phase 2. Define evaluation objectives and questions</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#phase-3-develop-and-test-data-collection-tools">Phase 3. Develop and test data collection tools</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#phase-4-collect-and-manage-data">Phase 4. Collect and manage data</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#phase-5-analyze-data-and-interpret-findings">Phase 5. Analyze data and interpret findings</a></div><div class="toc-item toc-level-3"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#phase-6-communicate-findings-and-facilitate-use">Phase 6. Communicate findings and facilitate use</a></div><div class="toc-item toc-level-2"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#roles-and-responsibilities">Roles and responsibilities</a></div><div class="toc-item toc-level-2"><a href="file:///C:/Users/gilli/AppData/Local/Microsoft/Windows/INetCache/Content.Outlook/8OOOKFML/Black_Health_Alliance_All_Programs_Evaluation_Plan.html#meeting-agendas">Meeting agendas</a></div>
        </div>
        <h1 id="black-health-alliance-all-programs-draft-evaluation-plan">Black Health Alliance ‚Äî All Programs Draft Evaluation Plan</h1><p class="subtitle">Created on 2025-10-06 by LogicalOutcomes Evaluation Planner</p><p>This draft evaluation plan is a draft, supporting Black Health Alliance in a process of continuous improvement that will also demonstrate the impact of All Programs. The evaluation approach aims to provide useful recommendations for program staff, management, and funders.  Its aim is to help evaluation teams move quickly to data collection, analysis and engagement, minimizing the time for initial planning, logic modelling, creating an evaluation framework and so on. </p><p>This plan does not include citations or research references. It is based on the LogicalOutcomes Evaluation Planning Handbook by Gillian Kerr and Sophie Llewelyn, which describes a structured process that relies on general evidence about effective nonprofit programs, supported by an in-depth web search about the program itself. </p><p>We recommend that users also carry out a quick literature review to check that the program‚Äôs design is consistent with research and evidence about its effectiveness with the target population.  For a free research scan we suggest Consensus. Ask something like, ‚ÄòWhat are likely to be essential program delivery elements and critical success factors for (type of program) serving (target population)? You can export the report and attach it to this evaluation plan. </p><p>If the draft evaluation plan is not accurate, you can paste additional information about the program or community into the ‚ÄòAbout the Program‚Äô box and try the app again. Or you can just use it as a rough draft and make your own changes. </p><section class="content-section"><h2 id="program-summary-and-analysis">Program summary and analysis</h2><h3 id="summary-of-the-program">Summary of the program</h3><p>Black Health Alliance (BHA) is a community-led registered charity working to improve the health and well-being of Black communities in Canada. BHA focuses on the root causes of inequity‚Äîsocial determinants of health, health inequities, anti-Black racism, and building connected communities‚Äîby centering Black communities in defining the challenges and co-designing solutions.</p><p>Across All Programs, BHA advances three core pillars: Health Promotion &amp; Community Engagement; Research &amp; Policy; and Strategy, Design &amp; Implementation. Through culturally grounded outreach, community navigation, community-partnered research and policy work, and co-design with partners, BHA aims to increase access to culturally safe care, strengthen data and policy, and drive system changes that improve health outcomes for Black community members.</p><h3 id="program-overview">Program overview</h3><p>BHA‚Äôs All Programs span local, regional, and national initiatives that address priority issues identified by Black community members and partners. The Health Promotion &amp; Community Engagement pillar builds trust, elevates health literacy, and connects people to services through trusted messengers, community forums, campaigns, and navigation. The Research &amp; Policy pillar generates and translates evidence about Black health, advances ethical race-based data standards, and informs decision-makers through briefs, testimonies, and coalitions. The Strategy, Design &amp; Implementation pillar convenes communities and service providers to co-design, pilot, and scale solutions, while providing technical assistance and training to embed anti-Black racism and cultural safety into organizational practice.</p><p>A typical journey for a community member may include connecting with BHA at a community event or online, receiving culturally relevant information, and being referred or navigated to health and social services. For organizations, the journey often involves participating in a co-design lab, receiving training and technical assistance, implementing pilots, and adopting policy and practice improvements. As a backbone partner, BHA also aligns multi-sector actors around shared goals and measures to accelerate equitable systems change.</p><h3 id="activities">Activities</h3><p>Below are BHA‚Äôs activities from the perspective of community members and partners, grouped by BHA‚Äôs three pillars.</p><p><strong>Health promotion &amp; community engagement</strong></p><ul><li>Attend culturally grounded outreach events, town halls, and forums</li><li>Connect with trusted community ambassadors and peer navigators</li><li>Receive health promotion materials and digital content tailored to Black communities</li><li>Get referrals and navigation support to health and social services</li><li>Join peer groups and community networks to build connectedness</li><li>Participate in community surveys and feedback sessions</li></ul><p><strong>Research &amp; policy</strong></p><ul><li>Co-create and participate in community-partnered research projects</li><li>Share lived experience to inform needs assessments and data standards</li><li>Review and respond to policy briefs, testimonies, and calls to action</li><li>Engage in knowledge translation sessions with decision-makers</li><li>Help define ethical race-based data priorities and governance practices</li></ul><p><strong>Strategy, design &amp; implementation</strong></p><ul><li>Take part in co-design labs with service providers and system leaders</li><li>Test prototypes and pilots that improve access and cultural safety</li><li>Receive organizational training on anti-Black racism and cultural safety</li><li>Engage in implementation collaboratives and quality improvement cycles</li><li>Use toolkits, dashboards, and guidance to scale effective models</li><li>Participate in coalition-building to align efforts and resources</li></ul><h3 id="key-management-processes">Key management processes</h3><p>Several management processes must be properly implemented to make for an effective program. </p><ul><li>Feedback and quality control: Establish a continuous feedback loop with Black community members, ambassadors, partners, and staff. Use post-event pulse checks, quick SMS/QR surveys at events, monthly team debriefs, and a simple suggestion intake form to identify improvements to outreach, navigation, co-design practices, and training.</li><li>Participatory decision-making: Engage community members and partners in shaping the work through community advisory councils, co-design sessions, and research advisory committees. Compensate lived experience advisors fairly and publish ‚ÄúYou said, we did‚Äù updates to close the loop.</li><li>Staff development: Provide ongoing training in anti-Black racism frameworks, cultural safety, trauma- and violence-informed practice, facilitation, implementation support, and data ethics. Pair trainings with coaching and peer learning to support sustained practice change.</li><li>Resource management: Monitor budgets, staffing, and timelines across initiatives. Use a shared project tracker for events, research milestones, TA engagements, training sessions, and pilot implementation to manage scope, quality, and risk.</li><li>Partnership management: Maintain partnership MOUs, clarify roles, and schedule regular check-ins with community-based organizations, health and social service providers, researchers, and policy partners. Track partner engagement and satisfaction.</li><li>Ethical race-based data governance: Implement clear consent processes, data minimization, privacy and security protocols, and community data governance guidelines. Align with provincial standards where relevant and ensure transparent data use and reporting.</li><li>Cultural responsiveness and safety protocols: Apply culturally safe practices across all touchpoints (events, navigation, training). Build safeguards for psychological safety, harm reporting, and rapid response to incidents of racism or discrimination.</li></ul><h3 id="main-interest-groups">Main interest groups</h3><table class="standard-table"><thead><tr><th>Interest group</th><th>What they hope for</th><th>Program risks (from their perspective)</th><th>Risk mitigation strategies</th></tr></thead><tbody><tr><td>Black community members</td><td>Respectful, culturally safe support; easier access to care; visible improvements in well-being</td><td>Feeling tokenized; not seeing tangible benefits; privacy concerns with race-based data</td><td>Fair compensation; ‚ÄúYou said, we did‚Äù feedback loops; clear consent and data protections; fast, visible service linkages</td></tr><tr><td>Community ambassadors/peer navigators</td><td>Training, support, and recognition; manageable caseloads</td><td>Burnout; unclear role boundaries; safety concerns during outreach</td><td>Clear scopes and supervision; debriefs and mental health supports; safety protocols; recognition and growth pathways</td></tr><tr><td>BHA program staff</td><td>Clarity on priorities; manageable workload; professional development</td><td>Overextension across many initiatives; insufficient tools or data</td><td>Project scoping and staffing plans; phased timelines; practical toolkits; peer learning and coaching</td></tr><tr><td>BHA leadership and Board</td><td>Evidence of impact; financial sustainability; strategic alignment</td><td>Insufficient outcome data; scope creep; reputational risk</td><td>Shared measurement; quarterly dashboards; risk register; communications plan</td></tr><tr><td>Community-based organizations (CBOs)</td><td>Equitable partnerships; shared resources; joint impact</td><td>Misaligned expectations; administrative burden</td><td>MOUs and roles; co-planning calendars; lightweight reporting; recognition of partner contributions</td></tr><tr><td>Health and social service providers</td><td>Practical training and TA; improved client outcomes</td><td>Training without follow-through; limited capacity to implement changes</td><td>Pair training with implementation support; QI cycles; leadership buy-in and accountability</td></tr><tr><td>Researchers and academics</td><td>Ethical, rigorous community-partnered research; usable data</td><td>Tokenism; data governance conflicts; slow approvals</td><td>CBPR agreements; community review; clear ethics and governance protocols</td></tr><tr><td>Policymakers (municipal/provincial/federal)</td><td>Clear evidence and solutions; community legitimacy</td><td>Advocacy without feasible policy options; fragmented asks</td><td>Policy-ready briefs; coalition alignment on priorities; costed, staged recommendations</td></tr><tr><td>Funders and sponsors</td><td>Value for money; credible results; visibility of impact</td><td>Limited outcome attribution; inconsistent reporting</td><td>Theory of change; mixed-methods results; consistent reporting cadence and learning products</td></tr><tr><td>Community advisory councils</td><td>Real influence on decisions; timely information</td><td>Decisions made without their input; meeting fatigue</td><td>Co-created agendas; advance materials; respect honoraria; visible use of advice</td></tr><tr><td>Faith and cultural organizations</td><td>Inclusive events; recognition of their role</td><td>Cultural insensitivity; poor scheduling</td><td>Co-hosting and co-branding; calendar alignment; cultural protocols</td></tr></tbody></table><h3 id="areas-of-evaluation-focus">Areas of evaluation focus</h3><ol><li>Community member engagement and retention: Track engagement at events, forums, co-design sessions, trainings, and navigation follow-through; monitor drop-off points and reasons.</li><li>Cultural appropriateness: Assess whether activities and materials reflect Black communities‚Äô diverse cultures, languages, and experiences; evaluate perceived cultural safety.</li><li>Program accessibility: Identify barriers such as timing, location, transportation, childcare, language, digital access, and immigration status; monitor accommodations used.</li><li>Partnership effectiveness: Measure quality of collaboration with CBOs, providers, researchers, and policymakers; assess clarity of roles, shared goals, and follow-through.</li><li>Outcome achievement: Monitor short-, mid-, and long-term outcomes aligned to BHA‚Äôs pillars (knowledge, access, practice/policy change, system change).</li><li>Staff satisfaction and turnover: Track workload, role clarity, professional development, and retention for staff and community ambassadors.</li><li>Safety and well-being: Monitor safety incidents, psychological safety, and trauma- and violence-informed practice indicators for community members and staff.</li></ol></section><section class="content-section"><h2 id="program-evaluation-plan">Program evaluation plan</h2><p>This section outlines a full evaluation plan to evaluate All Programs, including roles, responsibilities and meeting agendas.</p><h3 id="evaluation-objectives">Evaluation objectives</h3><ol><li>Meet community member needs and help community members achieve their goals.</li><li>Achieve program goals and outcomes.</li><li>Improve program quality and fidelity.</li><li>Increase responsiveness to community members in the way activities and initiatives are provided.</li><li>Increase accessibility and equity in service provision (as defined by the program itself; e.g., for persons with disabilities, people living on low incomes, from defined racial or ethnic groups, for underserved groups in the target population).</li><li>Increase responsiveness to key interest groups (as defined by the program; e.g., to the broader community served, employees, volunteers, funders, donors).</li></ol><h3 id="evaluation-questions">Evaluation questions</h3><ol><li>What activities are provided by Black Health Alliance ‚Äî All Programs?</li><li>To what extent is Black Health Alliance ‚Äî All Programs being implemented as designed and meeting quality standards?</li><li>What are the characteristics of the populations served by the program?</li><li>What do community members think about activities and initiatives and what are their suggestions?</li><li>What do staff and other key interest groups think about activities and initiatives and what are their suggestions?</li><li>To what extent are community members meeting their goals?</li><li>What short-term and mid-term changes are community members experiencing?</li><li>What evidence suggests the program is contributing to its desired long-term impact?</li></ol><h3 id="logic-model">Logic model</h3><div class="logic-model-container">
        <h4 style="margin: 0 0 1rem 0; color: #1e40af; text-align: center;">All Programs Logic Model</h4>
        <table class="logic-model-table">
          <thead><tr><th><strong>INPUTS</strong></th><th><strong>ACTIVITIES</strong></th><th><strong>OUTPUTS</strong></th><th><strong>SHORT-TERM OUTCOMES</strong></th><th><strong>MID-TERM OUTCOMES</strong></th><th><strong>LONG-TERM OUTCOMES</strong></th></tr></thead>
          <tbody><tr><td>‚Ä¢ Community leadership<br>‚Ä¢ Staff expertise<br>‚Ä¢ Program funding<br>‚Ä¢ Partnerships &amp; MOUs<br>‚Ä¢ Advisory councils<br>‚Ä¢ Race-based data standards<br>‚Ä¢ Digital platforms<br>‚Ä¢ Strategic plan 2022‚Äì2025</td><td>‚Ä¢ Engage communities<br>‚Ä¢ Train ambassadors<br>‚Ä¢ Deliver events/ forums<br>‚Ä¢ Provide navigation/ referrals<br>‚Ä¢ Conduct research/ analysis<br>‚Ä¢ Develop policy briefs<br>‚Ä¢ Facilitate co-design labs<br>‚Ä¢ Pilot interventions<br>‚Ä¢ Provide TA/ training<br>‚Ä¢ Run QI collaboratives<br>‚Ä¢ Build coalitions<br>‚Ä¢ Translate knowledge</td><td>‚Ä¢ # community members engaged<br>‚Ä¢ # events/ sessions<br>‚Ä¢ # ambassadors trained<br>‚Ä¢ # referrals made<br>‚Ä¢ # trainings delivered<br>‚Ä¢ # TA engagements<br>‚Ä¢ # research reports<br>‚Ä¢ # policy briefs<br>‚Ä¢ # co-design sessions<br>‚Ä¢ # pilots launched<br>‚Ä¢ # partners engaged<br>‚Ä¢ # dashboards/ reports</td><td>‚Ä¢ Increased health knowledge<br>‚Ä¢ Greater trust in services<br>‚Ä¢ Improved cultural safety perception<br>‚Ä¢ Stronger connectedness<br>‚Ä¢ Provider knowledge improved<br>‚Ä¢ Shared agendas set<br>‚Ä¢ Better data availability</td><td>‚Ä¢ Increased service uptake<br>‚Ä¢ Improved navigation follow-through<br>‚Ä¢ Organizational policy changes<br>‚Ä¢ Adopted data standards<br>‚Ä¢ Practice changes in care<br>‚Ä¢ Stronger partnerships<br>‚Ä¢ Prototypes implemented</td><td>‚Ä¢ Reduced health inequities<br>‚Ä¢ Improved well-being<br>‚Ä¢ Reduced racism in care<br>‚Ä¢ Better mental health access<br>‚Ä¢ Higher screening rates<br>‚Ä¢ Sustained systems change<br>‚Ä¢ Connected communities</td></tr></tbody>
        </table>
      </div><h3 id="evaluation-framework-for-all-programs">Evaluation framework for All Programs</h3><p>This evaluation framework operationalizes the logic model using the standard structure from the LogicalOutcomes Evaluation Planning Handbook. It assumes a client record system tracks each participant. If no such system exists, focus on outputs and process measures rather than outcome measures, since results from surveys with low response rates will not be statistically valid.</p><table class="metrics-table"><thead><tr><th>Logic model element</th><th>Measure</th><th>Respondent</th><th>Mode of data collection</th><th>Comments</th></tr></thead><tbody><tr><td>OUTPUTS (reported quarterly)</td><td></td><td></td><td></td><td></td></tr><tr><td>Community members served</td><td># community members</td><td>Project manager</td><td>Analysis of client record system or staff interviews</td><td>Include demographic breakdown (e.g., age, gender, region, Black identities) compared with equity targets.</td></tr><tr><td>Activities and initiatives provided</td><td># events/ sessions; # trainings; # TA engagements; # co-design sessions; # pilots; # referrals</td><td>Project manager</td><td>Analysis of client record system or staff interviews</td><td>Track type, frequency, and reach. Compare with targets for each pillar.</td></tr><tr><td>Partner engagement</td><td># partners engaged; # MOUs; # coalition meetings</td><td>Project manager</td><td>Document review; partner tracker</td><td>Assess breadth and consistency of partnership activity.</td></tr><tr><td>Research and policy products</td><td># research reports; # policy briefs; # testimonies</td><td>Project manager</td><td>Document review</td><td>Include dissemination channels and reach.</td></tr><tr><td>Digital engagement</td><td># subscribers; # campaign impressions; # click-throughs</td><td>Project manager</td><td>Platform analytics</td><td>Track reach and engagement of digital health promotion.</td></tr><tr><td>Delivery milestones for evaluation</td><td># weeks +/- target; Quality rating; Thematic analysis of optional 'description' field</td><td>Project manager</td><td>Document review of progress reports; Observation or audit</td><td>Compare milestone delivery to plan; rate completeness, data quality, and ethics compliance.</td></tr><tr><td>SHORT-TERM OUTCOMES (reported quarterly, though some data collection may be on annual schedule)</td><td></td><td></td><td></td><td></td></tr><tr><td>Meet community member needs</td><td>Goal questionnaire</td><td>Community member</td><td>Questionnaire or interview</td><td>Collected in client record system or linked survey at events/navigation.</td></tr><tr><td>Increase responsiveness to community members</td><td>Suggestions; Impact interview; Community member satisfaction; # team debriefs; Thematic analysis</td><td>Community member; Reviewer</td><td>Questionnaire or interview; Observation or audit</td><td>Multiple languages and formats. Focus on actionable feedback; minimize standalone ‚Äúsatisfaction‚Äù items.</td></tr><tr><td>Improve program quality and fidelity</td><td>Implementation fidelity/ program quality; Analysis of process data</td><td>Reviewer</td><td>Observation or audit; Analysis of client record system</td><td>Include checks on co-design practices, training + TA pairing, and QI cycle adherence. Process data includes time-to-navigation, referral completion.</td></tr><tr><td>Increase accessibility and equity to services</td><td>Suggestions; Impact interview; Analysis of intakes and dropouts vs. target population</td><td>Community member; Reviewer</td><td>Questionnaire or interview; Observation or audit</td><td>Track accommodations (childcare, transport, language, virtual options). Adjust outreach to underserved segments.</td></tr><tr><td>Increase responsiveness to interest groups</td><td>Suggestions; Impact interview; Occasional satisfaction surveys</td><td>Interest group member</td><td>Questionnaire or interview; Observation or audit</td><td>Groups include: CBO partners, health/social providers, researchers, policymakers, funders, advisory councils, ambassadors.</td></tr><tr><td>Cultural safety and trust</td><td>Perceived cultural safety; Trust in providers/systems</td><td>Community member</td><td>Brief scales embedded in service flow</td><td>Collect rapidly post-engagement and periodically.</td></tr><tr><td>MID-TERM OUTCOMES (reported annually)</td><td></td><td></td><td></td><td></td></tr><tr><td>Achieve community member goals</td><td>Success rate of community member goals ‚Äì self-identified</td><td>Community member</td><td>Questionnaire or interview</td><td>Include goals such as access to services, improved knowledge, navigation success.</td></tr><tr><td>Achieve program goals</td><td>Success rate for program goals and outcomes</td><td>Interest group member</td><td>Questionnaire or interview; Analysis of client record system</td><td>Goals per pillar: knowledge and reach; access and navigation; policy/practice adoption; data standards and use; coalition progress.</td></tr><tr><td>Increase program effectiveness and efficiency</td><td>Improvements in processes; Increased cost-benefit ratio for high quality outputs and goal achievements</td><td>Employee; Reviewer</td><td>Questionnaire or interview; Observation or audit</td><td>Include staff workload balance, cycle time for referrals, and TA-to-implementation ratios.</td></tr><tr><td>Meet key interest group needs</td><td>Analysis of interest group responses</td><td>Interest group member; Reviewer</td><td>Questionnaire or interview; Observation or audit</td><td>Groups: BHA staff, CBO partners, providers, researchers, policymakers, funders, advisory councils.</td></tr><tr><td>Improve organizational capacity</td><td>Specificity and responsiveness of organizational plans</td><td>Project manager or Reviewer</td><td>Observation or audit</td><td>Track inclusion of evaluation findings in plans, budgets, and timelines; monitor Board oversight.</td></tr><tr><td>Practice and policy change</td><td># organizations adopting policies; # practice changes; equity dashboards in use</td><td>Provider/ organization lead</td><td>Document review; key informant interviews</td><td>Verify adoption and early effects through audit/feedback.</td></tr><tr><td>LONG-TERM OUTCOMES (for ongoing monitoring 2+ years once monitoring and evaluation system is mature)</td><td></td><td></td><td></td><td></td></tr><tr><td>Achieve program outcomes</td><td>Aggregated mid-term program outcomes or separate long-term evaluation project</td><td>N/A</td><td>N/A</td><td>Long-term outcomes: reduced inequities; improved well-being; reduced racism in care; better mental health access; higher screening; sustained systems change.</td></tr><tr><td>Achieve community outcomes</td><td>Separate evaluation project</td><td>N/A</td><td>N/A</td><td>Includes population-level indicators and policy shifts aligned to BHA‚Äôs strategic focus areas.</td></tr><tr><td>Improve organizational sustainability</td><td>Separate evaluation project</td><td>N/A</td><td>N/A</td><td>Track funding diversity, staff retention, leadership capacity, and partner network strength.</td></tr></tbody></table></section><section class="content-section"><h2 id="evaluation-phases">Evaluation phases</h2><p>This evaluation will be conducted in four overlapping phases to ensure a structured and participatory process.</p><h3 id="overview">Overview</h3><p>This evaluation will follow a compressed timeline to provide rapid, useful feedback. The phases are designed to build on each other, from foundational planning and engagement to data analysis and reporting. The intent is to focus evaluation resources as much as possible on understanding and responding to interest group perspectives and on improving program quality.</p><p>The evaluation project includes the following activities divided into four overlapping phases:</p><ul><li>Planning and initiation: Activities 1 ‚Äì 5 (duration: 3 to 8 weeks)</li><li>Design and development: Activities 5 ‚Äì 9 (duration: 1 to 12 weeks)</li><li>Implementation and analysis: Activities 9 ‚Äì 11 (ongoing until project completion)</li><li>Communication and discussion: Activities 11 ‚Äì 12 (duration: 3 to 6 weeks)</li></ul><h3 id="phase-1-engage-the-project-sponsor-team-members-and-key-decision-makers">Phase 1. Engage the project sponsor, team members, and key decision-makers</h3><ul><li>Confirm evaluation scope, budget and delivery date for the final report.</li><li>Define the main roles and responsibilities for the evaluation project, including the manager who is overseeing the project and who will be taking the recommendations to senior management.</li><li>Identify and invite members to an Evaluation Advisory Committee.</li><li>Define the timelines, resources (including staff effort for interviews and data collection) and the decision process for approval of final report.</li></ul><h3 id="phase-2-define-evaluation-objectives-and-questions">Phase 2. Define evaluation objectives and questions</h3><ul><li>Facilitate a meeting with the advisory committee to discuss and revise the evaluation objectives and questions.</li><li>Ensure evaluation questions are relevant to staff, meaningful to community members, and credible to funders.</li><li>Confirm or revise the specific activities that are delivered by the program and that are essential to the program. Include direct services to community members as well as other essential elements such as collaboration with other organizations, staff training and financial management.</li><li>Confirm or revise the key interest groups that should be engaged in data collection and/or discussion of the results.</li><li>Finalize the evaluation framework, confirming that the indicators are measurable and meaningful.</li></ul><h3 id="phase-3-develop-and-test-data-collection-tools">Phase 3. Develop and test data collection tools</h3><ul><li>Review and possibly adapt current client record system if one exists to assess whether it can generate reports for community member goals, milestones and activities. For example, every community member should be asked what they hope to get from the services, and if feasible asked later if they achieved their goals.</li><li>Draft all data collection tools (surveys, interview guides, tracking sheets). If possible, adapt and customize them from existing validated data collection tools to save time and improve validity.</li><li>Pilot test the tools with a small group of community members and staff to ensure clarity and cultural appropriateness.</li><li>Refine tools based on pilot feedback.</li></ul><h3 id="phase-4-collect-and-manage-data">Phase 4. Collect and manage data</h3><ul><li>Train staff or designated data collectors on protocols to ensure data quality and consistency.</li><li>Deploy surveys, conduct interviews, and analyze client records as per the evaluation framework.</li><li>Ensure ethical protocols, including informed consent and data confidentiality, are strictly followed.</li><li>Frequent interim reports will assess whether the data appears to be accurate and whether it captures feedback from defined interest groups and demographic groups.</li><li>If necessary, additional demographic segments may be targeted with additional interviews or financial incentives.</li></ul><h3 id="phase-5-analyze-data-and-interpret-findings">Phase 5. Analyze data and interpret findings</h3><ul><li>Clean and analyze quantitative and qualitative data.</li><li>Deliver reports frequently to appropriate staff and interest groups with a focus on recommended actions. Emerging findings may be tested with follow-up interviews or more detailed reports.</li><li>Notes from staff meetings will be reviewed for evidence of actions that have been taken or recommendations that have been made as a result of the reports.</li><li>Hold a "sense-making" session with the advisory committee and staff to interpret the initial findings, discuss implications, and co-develop recommendations. This participatory step is crucial for ensuring the results are understood and owned by the team.</li></ul><h3 id="phase-6-communicate-findings-and-facilitate-use">Phase 6. Communicate findings and facilitate use</h3><ul><li>Draft a comprehensive evaluation report with a clear executive summary.</li><li>Develop tailored communication materials for different groups (e.g., one-page summary for the board, presentation for staff, stories for a newsletter).</li><li>Facilitate a final meeting to discuss the report and create an action plan for implementing the recommendations.</li></ul></section><section class="content-section"><h2 id="roles-and-responsibilities">Roles and responsibilities</h2><p>It is necessary to involve senior managers and decision-makers in the evaluation process so that the resulting information will be relevant and credible to them. They should be engaged at three stages:</p><ul><li>Defining objectives, roles and key interest groups at the beginning of the evaluation.</li><li>Engaging with data as soon as it starts to be collected and then occasionally throughout the project.</li><li>Engaging with the final recommendations and action plans near the end of the evaluation.</li></ul><p>In addition, representatives of the organization need to be involved more deeply in:</p><ul><li>Defining the program services and key processes.</li><li>Defining project timelines and tracking quality.</li><li>Configuring the client record system and refining the data collection tools.</li></ul><p>And of course members of key interest groups will be asked for input as part of the data collection activities.</p><p>There are four essential roles for a successful evaluation project:</p><p><strong>Sponsor</strong> (generally a senior manager who will be responsible for implementing recommendations)</p><ul><li>Provide guidance regarding overall objectives and constraints of project</li><li>Liaise with the organization's senior management and manage organizational expectations and scope issues as appropriate</li><li>Communicate with internal and external interest groups regarding project progress</li><li>Remove roadblocks to project success and respond to project risks and problems as they are identified by the Project Manager or Liaison</li><li>Approve significant changes to the project scope, timeline, budget, or quality if required</li><li>Review and approve project documents and other deliverables</li></ul><p><strong>Liaison</strong> (generally a manager at the organization reporting to the Project Sponsor)</p><ul><li>Act as the primary contact person with the evaluator</li><li>Liaise with the Project Sponsor and take on their responsibilities as delegated</li><li>Act as a project manager from the organization's side, e.g., scheduling meetings with program staff, negotiating with I.T. staff</li></ul><p><strong>Project Owner</strong> (generally a senior external evaluator)</p><ul><li>Provide project leadership for the evaluation as a whole</li><li>Define project methodologies and advise on strategic issues</li><li>Author, review and approve project documents as assigned</li><li>Manage and resolve team-level risks, issues, and changes</li><li>Remove roadblocks to project success and respond to project risks and problems as they are identified by the Project Manager or Project Sponsor</li><li>Review and provide detailed feedback regarding all project documents and deliverables</li></ul><p><strong>Project Manager</strong> (generally an external evaluator reporting to the Project Owner)</p><ul><li>Act as liaison to the organization for operational issues</li><li>Monitor project scope, quality, schedule, resources, costs and risks</li><li>Coordinate implementation of project work</li><li>Ensure project plan, schedule, and budget are up-to-date; detect and manage discrepancies</li><li>Report risks, delays and problems to Project Owner and Project Sponsor as they arise</li><li>Author, review and approve project documents as assigned to ensure the quality standards are met</li><li>Arrange and follow-up on team meetings</li><li>Manage and contribute to data collection, analysis and report writing</li><li>Provide leadership and manage work as appropriate</li></ul><p><strong>Program staff</strong> (one or more representatives of the people who will actually implement service improvements and experience changes in their workplace)</p><p>Other common roles include I.T. specialists, program community members and representatives from key constituencies.</p></section><section class="content-section"><h2 id="meeting-agendas">Meeting agendas</h2><p>At a bare minimum, not including meetings that involve only the Project Liaison and Project Manager, the project should have four structured meetings with organizational representatives, e.g., by holding a full day workshop to combine steps 2 and 3.</p><p>Following are agenda templates for these key meetings. The attendees represent the minimum roles required for a successful evaluation. Other roles may be invited depending on the needs of the project.</p><table class="standard-table"><thead><tr><th>Meeting Purpose</th><th>Deliverables</th><th>Minimum attendees (always includes project manager)</th><th>Notes</th></tr></thead><tbody><tr><td>1. Initiate the project</td><td>Draft of Evaluation Plan</td><td>Liaison</td><td>The agenda for this meeting is to clarify and confirm the evaluation's objectives, methodology, roles and timelines, using this report as a working draft. The Project Manager and Liaison revise this report with input from Statement of Work, proposal and program documents.</td></tr><tr><td>2. Define objectives, roles and key interest groups</td><td>Approved Evaluation Plan</td><td>Project Owner, Sponsor, Liaison, program staff</td><td>This meeting involves the organization's decision-makers and program staff to build engagement in the evaluation, to decide on priorities, and to commit on how they will handle problems as they arise. The completed Evaluation Plan is approved by the Sponsor shortly after the meeting.</td></tr><tr><td>3. Configure client record system and data collection tools</td><td>Revise or design client record system and approved data collection tools</td><td>Liaison, program staff</td><td>Use existing tools as much as possible. If further discussion needed offer additional meetings to subgroup</td></tr><tr><td>4. Track progress and troubleshoot problems</td><td>Progress report</td><td>Liaison</td><td>This can be combined with other meetings. The purpose is to discuss delays and solve problems as they arise.</td></tr><tr><td>5. Engage with data</td><td>Meeting notes with actions</td><td>Liaison, program staff (monthly at first, then bimonthly)</td><td>These meetings should be a recurring agenda item in regular program staff meetings, if feasible. Part of the purpose is to get staff accustomed to responding to community member feedback in their staff meetings as a normal reflective practice. Emerging conclusions should be addressed early and often so that staff get a chance to contribute to recommendations before they are presented to senior management.</td></tr><tr><td>6. Engage with recommendations</td><td>Revised conclusions and recommendations</td><td>Project Owner, Project Sponsor, Liaison, Project Owner, program staff</td><td>This may require multiple meetings with different interest groups, with revisions at each stage incorporating their feedback. The meetings should present only conclusions and recommendations to encourage discussion. Technical details should be available for questions and circulated to interested interest groups.</td></tr></tbody></table><hr>
<p>Generated by LogicalOutcomes Evaluation Planner on 2025-10-06</p></section>
    </div>

</body></html>